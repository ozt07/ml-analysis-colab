# ğŸ«€ AnÃ¡lisis de Enfermedad CardÃ­aca con Machine Learning

## ğŸ“‹ DescripciÃ³n del Proyecto
AnÃ¡lisis predictivo de enfermedades cardÃ­acas utilizando **algoritmos de Machine Learning** en **Google Colab (SaaS)**.  
El objetivo principal es **identificar patrones clÃ­nicos** y **predecir la presencia de enfermedades cardÃ­acas** a partir de datos mÃ©dicos estructurados.

---

## ğŸ¯ Objetivos

- Realizar anÃ¡lisis exploratorio completo (EDA)  
- Implementar y comparar modelos de clasificaciÃ³n  
- Identificar factores de riesgo principales  
- Generar insights accionables para diagnÃ³stico temprano  

---

## ğŸ“Š Dataset

| CaracterÃ­stica | DescripciÃ³n |
|----------------|-------------|
| **Nombre** | Heart Disease Dataset (Cleveland) |
| **Fuente** | [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/heart+disease) |
| **Muestras** | 303 registros |
| **Variables** | 13 caracterÃ­sticas clÃ­nicas + 1 target |
| **Tipo de Problema** | ClasificaciÃ³n binaria *(Presencia de enfermedad cardÃ­aca: SÃ­/No)* |

---

## ğŸ› ï¸ MetodologÃ­a

### 1ï¸âƒ£ ExploraciÃ³n de Datos (EDA)
- AnÃ¡lisis de distribuciones y correlaciones  
- DetecciÃ³n de valores atÃ­picos y faltantes  
- Visualizaciones exploratorias (mapas de calor, histogramas, boxplots)

### 2ï¸âƒ£ Preprocesamiento
- ImputaciÃ³n de valores faltantes (moda)  
- Escalado de variables numÃ©ricas con `StandardScaler`  
- DivisiÃ³n **train/test (80/20)** con estratificaciÃ³n  

### 3ï¸âƒ£ Modelado con Machine Learning
**Algoritmos implementados:**
- RegresiÃ³n LogÃ­stica *(modelo base)*  
- Random Forest Classifier *(modelo principal)*  
- OptimizaciÃ³n con **GridSearchCV**

### 4ï¸âƒ£ EvaluaciÃ³n
**MÃ©tricas utilizadas:**
- Exactitud (Accuracy)  
- PrecisiÃ³n (Precision)  
- Recall  
- F1-Score  
- Matriz de confusiÃ³n  
- Importancia de variables  

---

## ğŸ“ˆ Resultados Principales

### ğŸ”¹ Rendimiento de Modelos

| Modelo | Exactitud | PrecisiÃ³n | Recall | F1-Score |
|--------|------------|-----------|---------|-----------|
| **RegresiÃ³n LogÃ­stica** | 86.9% | 81.2% | 92.9% | 86.7% |
| **Random Forest (Base)** | 90.2% | 84.4% | 96.4% | 90.0% |
| **Random Forest (Optimizado)** | 88.5% | 81.8% | 96.4% | 88.5% |

### ğŸ”¹ Variables MÃ¡s Importantes
1. **thal** (Defecto talasÃ©mico) â€” 14.5%  
2. **cp** (Tipo de dolor de pecho) â€” 13.6%  
3. **thalach** (Frecuencia cardÃ­aca mÃ¡xima) â€” 11.8%  
4. **ca** (NÃºmero de vasos principales) â€” 11.0%  
5. **oldpeak** (DepresiÃ³n ST) â€” 10.2%

---

## ğŸ’¡ Insights Clave

### ğŸ” Hallazgos Principales
- La **frecuencia cardÃ­aca mÃ¡xima** es un predictor fuerte: valores bajos indican mayor riesgo.  
- El **tipo de dolor de pecho** es crÃ­tico para el diagnÃ³stico temprano.  
- Los **defectos talasÃ©micos** mostraron la mayor importancia predictiva.  
- El modelo **detecta correctamente la mayorÃ­a de casos positivos** (Recall del 96.4%).

### ğŸ©º Recomendaciones MÃ©dicas
- Monitorear la frecuencia cardÃ­aca durante el ejercicio.  
- Evaluar el tipo de dolor de pecho como sÃ­ntoma clave.  
- Considerar pruebas de talasemia en pacientes de riesgo.  
- Usar angiografÃ­a para evaluar vasos afectados.  

---

## ğŸš€ CÃ³mo Reproducir el AnÃ¡lisis

### ğŸ”§ Prerrequisitos
Instalar dependencias principales:
```bash
pip install pandas numpy matplotlib seaborn scikit-learn
```

### â–¶ï¸ EjecuciÃ³n
1. Abrir el notebook `notebooks/data_analysis.ipynb` en **Google Colab**  
2. Ejecutar las celdas secuencialmente  
3. Los datos se descargan automÃ¡ticamente desde **UCI Repository**

---

## ğŸ“ Estructura del Repositorio

```text
ml-analysis-colab/
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ data_analysis.ipynb
â”‚   â””â”€â”€ exploratory_analysis.ipynb
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ visualizations/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ reports/
â”œâ”€â”€ docs/
â””â”€â”€ README.md
```

---

## ğŸ”— Enlaces Importantes
- ğŸ“˜ [Notebook en Google Colab](#)  
- ğŸ§© [Dataset Original - UCI Repository](https://archive.ics.uci.edu/ml/datasets/heart+disease)  
- ğŸ¥ [Video de SustentaciÃ³n](#)  

---

## âš ï¸ Limitaciones
- Dataset pequeÃ±o (303 muestras)  
- Algunas variables con valores faltantes  
- Falta validaciÃ³n externa en nuevos conjuntos de datos  

---

## ğŸ› ï¸ TecnologÃ­as Utilizadas
- **Plataforma:** Google Colab (SaaS)  
- **Lenguaje:** Python 3.x  
- **LibrerÃ­as:** pandas, numpy, scikit-learn, matplotlib, seaborn  

---

## ğŸ‘¥ Autor
**Ã“scar Fernando Tovar Prieto**  
ğŸ“˜ *ComputaciÃ³n en la Nube - Actividad 5*  
Universidad Los Libertadores  
